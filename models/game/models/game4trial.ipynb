{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550e3b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moufid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from typing import Dict, List, Tuple\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58433211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Collecting pydantic (from google-generativeai)\n",
      "  Downloading pydantic-2.11.4-py3-none-any.whl.metadata (66 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.0rc0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->google-generativeai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->google-generativeai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions (from google-generativeai)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->google-generativeai)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\moufid\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.2)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moufid\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.5/1.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.0rc0-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/13.3 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/13.3 MB 2.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.6/13.3 MB 2.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/13.3 MB 2.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/13.3 MB 2.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.6/13.3 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.4/13.3 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.2/13.3 MB 2.5 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.5/13.3 MB 2.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/13.3 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.7/13.3 MB 2.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.0/13.3 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.0/13.3 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 5.0/13.3 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.2/13.3 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 5.5/13.3 MB 1.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 5.8/13.3 MB 1.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 6.3/13.3 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 6.6/13.3 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 7.1/13.3 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 7.3/13.3 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 7.9/13.3 MB 1.7 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 8.4/13.3 MB 1.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.9/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.2/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.2/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 9.2/13.3 MB 1.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 9.4/13.3 MB 1.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 9.7/13.3 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.2/13.3 MB 1.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.5/13.3 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 11.0/13.3 MB 1.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 11.5/13.3 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 12.1/13.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.3 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.8/13.3 MB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 1.7 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.4-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/2.0 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 986.7 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 986.7 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 919.0 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 987.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.3 MB 1.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.8/4.3 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 1.3/4.3 MB 1.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 1.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.1/4.3 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 2.6/4.3 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, typing-extensions, pyasn1, protobuf, httplib2, grpcio, cachetools, annotated-types, typing-inspection, rsa, pydantic-core, pyasn1-modules, proto-plus, googleapis-common-protos, pydantic, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.62.2\n",
      "    Uninstalling grpcio-1.62.2:\n",
      "      Successfully uninstalled grpcio-1.62.2\n",
      "Successfully installed annotated-types-0.7.0 cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc0 google-api-python-client-2.169.0 google-auth-2.40.1 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.4 pydantic-core-2.33.2 rsa-4.9.1 typing-extensions-4.13.2 typing-inspection-0.4.0 uritemplate-4.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Moufid\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\n",
      "torchaudio 2.2.2+cpu requires torch==2.2.2, but you have torch 2.7.0 which is incompatible.\n",
      "torchvision 0.17.2 requires torch==2.2.2, but you have torch 2.7.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "400c8a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API Key loaded successfully!\n",
      "‚úÖ Dataset loaded successfully with 79 scenarios!\n"
     ]
    }
   ],
   "source": [
    "# Load Gemini API Key\n",
    "def load_api_key() -> None:\n",
    "    env_path = \"../models/key.env\"\n",
    "    load_dotenv(env_path)\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\") or \"AIzaSyCcE1d9GrpAGiQh3Xrqlhs5E_wx4oAZ4d8\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"‚ùå Gemini API Key not found.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"‚úÖ Gemini API Key loaded successfully!\")\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset() -> List[Dict]:\n",
    "    dataset_path = \"../datasets/game.json\"\n",
    "    try:\n",
    "        with open(dataset_path, \"r\") as file:\n",
    "            dataset = json.load(file)\n",
    "        if \"intents\" not in dataset:\n",
    "            raise ValueError(\"‚ùå Dataset must have an 'intents' key.\")\n",
    "        for intent in dataset[\"intents\"]:\n",
    "            if \"scenario\" not in intent or \"responses\" not in intent:\n",
    "                raise ValueError(f\"‚ùå Each intent must have 'scenario' and 'responses': {intent}\")\n",
    "            for response in intent[\"responses\"]:\n",
    "                if \"option\" not in response or \"reward\" not in response:\n",
    "                    raise ValueError(\"‚ùå Each response must have 'option' and 'reward'.\")\n",
    "        print(f\"‚úÖ Dataset loaded successfully with {len(dataset['intents'])} scenarios!\")\n",
    "        return dataset[\"intents\"]\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"‚ùå Dataset file '{dataset_path}' not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"‚ùå Failed to parse JSON file '{dataset_path}'.\")\n",
    "\n",
    "# Generate new scenarios using Gemini\n",
    "def generate_new_scenarios(emotion: str = \"stress\", num_scenarios: int = 5) -> List[Dict]:\n",
    "    prompt = (\n",
    "        f\"Generate {num_scenarios} emotional decision-making scenarios for a user feeling {emotion}. \"\n",
    "        f\"Each scenario should include:\\n\"\n",
    "        f\"- 'scenario': a brief emotional situation,\\n\"\n",
    "        f\"- 'emotion': the emotion (e.g., 'stress', 'fear', etc.),\\n\"\n",
    "        f\"- 'difficulty': one of ['easy', 'medium', 'hard'],\\n\"\n",
    "        f\"- 'responses': a list of 4 options, each with 'option' text and a numeric 'reward'.\\n\"\n",
    "        f\"Format the output as valid JSON.\\n\"\n",
    "    )\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-pro\")\n",
    "        response = model.generate_content(prompt)\n",
    "        generated_data = json.loads(response.text.strip())\n",
    "        if isinstance(generated_data, dict):\n",
    "            return [generated_data]\n",
    "        return generated_data\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error generating scenarios: {e}\")\n",
    "        return []\n",
    "\n",
    "# Stress tracking\n",
    "class StressMetrics:\n",
    "    def __init__(self):\n",
    "        self.stress_level = 0\n",
    "        self.stress_history = []\n",
    "        self.response_times = []\n",
    "        self.incorrect_choices = 0\n",
    "        self.correct_choices = 0\n",
    "\n",
    "    def update_stress(self, reward: float, response_time: float) -> None:\n",
    "        stress_change = 0\n",
    "        if reward < 0:\n",
    "            self.incorrect_choices += 1\n",
    "            stress_change = 0.2\n",
    "        else:\n",
    "            self.correct_choices += 1\n",
    "            stress_change = -0.1\n",
    "        stress_change += min(response_time / 10, 0.5)\n",
    "        self.stress_level = max(0, min(1, self.stress_level + stress_change))\n",
    "        self.stress_history.append(self.stress_level)\n",
    "        self.response_times.append(response_time)\n",
    "\n",
    "    def get_summary(self) -> Dict:\n",
    "        return {\n",
    "            \"current_stress\": self.stress_level,\n",
    "            \"average_stress\": sum(self.stress_history) / len(self.stress_history) if self.stress_history else 0,\n",
    "            \"correct_choices\": self.correct_choices,\n",
    "            \"incorrect_choices\": self.incorrect_choices,\n",
    "            \"average_response_time\": sum(self.response_times) / len(self.response_times) if self.response_times else 0\n",
    "        }\n",
    "\n",
    "# Environment\n",
    "class EmotionGameEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human']}\n",
    "\n",
    "    def __init__(self, additional_scenarios: List[Dict] = None):\n",
    "        super().__init__()\n",
    "        self.dataset = load_dataset()\n",
    "        if additional_scenarios:\n",
    "            self.dataset += additional_scenarios\n",
    "        self.stress_metrics = StressMetrics()\n",
    "        self.interaction_history = []\n",
    "        self.current_episode = 0\n",
    "        self.emotions = [\"sad\", \"angry\", \"happy\", \"stress\", \"neutral\", \"fear\", \"anxious\"]\n",
    "        self.difficulty_levels = [\"easy\", \"medium\", \"hard\"]\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"emotion\": spaces.Discrete(len(self.emotions)),\n",
    "            \"difficulty\": spaces.Discrete(len(self.difficulty_levels))\n",
    "        })\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.max_episode_length = 10\n",
    "        self.state = None\n",
    "        self.current_scenario = None\n",
    "        self.episode_step = 0\n",
    "        self.available_scenarios = self._categorize_scenarios()\n",
    "\n",
    "    def _categorize_scenarios(self) -> Dict[str, List[Dict]]:\n",
    "        categorized = defaultdict(list)\n",
    "        for scenario in self.dataset:\n",
    "            categorized[scenario.get(\"emotion\", \"neutral\")].append(scenario)\n",
    "        return categorized\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_episode += 1\n",
    "        self.episode_step = 0\n",
    "        emotion = random.choice(self.emotions)\n",
    "        difficulty = random.choice(self.difficulty_levels)\n",
    "        possible_scenarios = [\n",
    "            s for s in self.available_scenarios.get(emotion, [])\n",
    "            if s.get(\"difficulty\") == difficulty\n",
    "        ]\n",
    "        if not possible_scenarios:\n",
    "            possible_scenarios = self.dataset\n",
    "        self.current_scenario = random.choice(possible_scenarios)\n",
    "        self.state = {\n",
    "            \"emotion\": self.emotions.index(emotion),\n",
    "            \"difficulty\": self.difficulty_levels.index(difficulty)\n",
    "        }\n",
    "        return self.state, {}\n",
    "\n",
    "    def step(self, action: int) -> Tuple[Dict, float, bool, bool, Dict]:\n",
    "        start_time = time.time()\n",
    "        self.episode_step += 1\n",
    "        try:\n",
    "            responses = self.current_scenario[\"responses\"]\n",
    "            if action >= len(responses):\n",
    "                reward = -1\n",
    "                response_text = \"Invalid choice\"\n",
    "            else:\n",
    "                response_data = responses[action]\n",
    "                reward = response_data[\"reward\"]\n",
    "                response_text = response_data.get(\"text\", response_data.get(\"option\", \"\"))\n",
    "                difficulty = self.difficulty_levels[self.state[\"difficulty\"]]\n",
    "                if difficulty == \"hard\":\n",
    "                    reward *= 1.5\n",
    "                elif difficulty == \"easy\":\n",
    "                    reward *= 0.8\n",
    "        except Exception:\n",
    "            reward = -1\n",
    "            response_text = \"Error in scenario\"\n",
    "\n",
    "        response_time = time.time() - start_time\n",
    "        self.stress_metrics.update_stress(reward, response_time)\n",
    "\n",
    "        self.interaction_history.append({\n",
    "            \"episode\": self.current_episode,\n",
    "            \"step\": self.episode_step,\n",
    "            \"emotion\": self.emotions[self.state[\"emotion\"]],\n",
    "            \"scenario\": self.current_scenario[\"scenario\"],\n",
    "            \"action\": action,\n",
    "            \"response\": response_text,\n",
    "            \"reward\": reward,\n",
    "            \"response_time\": response_time,\n",
    "            \"stress_level\": self.stress_metrics.stress_level\n",
    "        })\n",
    "\n",
    "        done = self.episode_step >= self.max_episode_length or reward < -0.5\n",
    "\n",
    "        info = {\n",
    "            \"scenario\": self.current_scenario[\"scenario\"],\n",
    "            \"response\": response_text,\n",
    "            \"stress_level\": self.stress_metrics.stress_level,\n",
    "            \"correct_response\": self.current_scenario.get(\"correct_response\", \"\"),\n",
    "            \"difficulty\": self.current_scenario.get(\"difficulty\", self.difficulty_levels[self.state[\"difficulty\"]])\n",
    "        }\n",
    "\n",
    "        next_state = {\n",
    "            \"emotion\": self.state[\"emotion\"],\n",
    "            \"difficulty\": random.choice([\n",
    "                self.state[\"difficulty\"]] * 3 + [\n",
    "                max(0, self.state[\"difficulty\"] - 1),\n",
    "                min(len(self.difficulty_levels)-1, self.state[\"difficulty\"] + 1)\n",
    "            ])\n",
    "        }\n",
    "\n",
    "        return next_state, reward, done, False, info\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"\\nEmotion: {self.emotions[self.state['emotion']]}, \"\n",
    "              f\"Difficulty: {self.difficulty_levels[self.state['difficulty']]}, \"\n",
    "              f\"Scenario: {self.current_scenario['scenario']}, \"\n",
    "              f\"Stress Level: {self.stress_metrics.stress_level:.2f}\")\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.interaction_history\n",
    "\n",
    "    def get_stress_summary(self):\n",
    "        return self.stress_metrics.get_summary()\n",
    "\n",
    "# Gemini-based therapy\n",
    "def get_therapy_response(emotion: str, scenario: str, stress_level: float, history: List[Dict]) -> str:\n",
    "    recent_history = history[-3:] if history else []\n",
    "    context = \"\\n\".join(\n",
    "        f\"Previous interaction: When feeling {h['emotion']} in situation '{h['scenario']}', \"\n",
    "        f\"the response was '{h['response']}' resulting in reward {h['reward']:.1f} and stress {h['stress_level']:.2f}.\"\n",
    "        for h in recent_history\n",
    "    )\n",
    "\n",
    "    therapy_approaches = {\n",
    "        \"stress\": \"cognitive behavioral therapy\",\n",
    "        \"anxious\": \"grounding and mindfulness\",\n",
    "        \"angry\": \"anger management\",\n",
    "        \"sad\": \"positive reframing\",\n",
    "        \"happy\": \"positive reinforcement\",\n",
    "        \"fear\": \"exposure therapy\",\n",
    "        \"neutral\": \"general counseling\"\n",
    "    }\n",
    "    approach = therapy_approaches.get(emotion, \"general counseling\")\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a compassionate AI therapist trained in CBT, DBT, and mindfulness.\\n\"\n",
    "        f\"The user feels {emotion} (stress level {stress_level:.2f}) in scenario: '{scenario}'.\\n\"\n",
    "        f\"Use {approach} to help them.\\n\"\n",
    "        f\"Here is context:\\n{context}\\nTherapeutic response:\"\n",
    "    )\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-pro\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ö†Ô∏è Error from Gemini: {e}\"\n",
    "\n",
    "# Training\n",
    "def train_rl_model(env: EmotionGameEnv, total_timesteps: int = 20000) -> PPO:\n",
    "    check_env(env)\n",
    "    eval_callback = EvalCallback(\n",
    "        env,\n",
    "        callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=5.0, verbose=1),\n",
    "        verbose=1,\n",
    "        eval_freq=1000,\n",
    "        best_model_save_path=\"./best_models/\"\n",
    "    )\n",
    "    model = PPO(\"MultiInputPolicy\", env, verbose=1, learning_rate=0.0003, tensorboard_log=\"./tensorboard_logs/\")\n",
    "    model.learn(total_timesteps=total_timesteps, callback=eval_callback)\n",
    "    model.save(\"emotional_rl_agent_enhanced\")\n",
    "    return model\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(env: EmotionGameEnv, model_path: str = \"emotional_rl_agent_enhanced\", num_tests: int = 5):\n",
    "    print(\"\\nüìä Evaluation Started\")\n",
    "    try:\n",
    "        model = PPO.load(model_path)\n",
    "    except:\n",
    "        print(\"Model not found.\")\n",
    "        return\n",
    "\n",
    "    for test in range(num_tests):\n",
    "        print(f\"\\n=== Test Case {test+1} ===\")\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            env.render()\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            emotion = env.emotions[obs[\"emotion\"]]\n",
    "            gpt_response = get_therapy_response(emotion, info[\"scenario\"], env.stress_metrics.stress_level, env.get_history())\n",
    "            print(f\"\\nTherapeutic Feedback: {gpt_response}\")\n",
    "\n",
    "# Entry point\n",
    "def main():\n",
    "    load_api_key()\n",
    "    mode = input(\"Choose mode: [1] Train, [2] Evaluate, [3] Gemini test only: \")\n",
    "\n",
    "    if mode == '3':\n",
    "        new_scenarios = generate_new_scenarios(emotion=\"stress\", num_scenarios=3)\n",
    "        if not new_scenarios:\n",
    "            print(\"‚ùå Failed to generate scenarios.\")\n",
    "            return\n",
    "        env = EmotionGameEnv(additional_scenarios=new_scenarios)\n",
    "        evaluate_model(env, num_tests=3)\n",
    "        return\n",
    "\n",
    "    env = EmotionGameEnv()\n",
    "\n",
    "    if mode == '1':\n",
    "        train_rl_model(env)\n",
    "    elif mode == '2':\n",
    "        evaluate_model(env, num_tests=3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fer_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
