{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef2fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Using cached google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Downloading google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from google-generativeai) (2.9.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic->google-generativeai)\n",
      "  Using cached pydantic_core-2.23.4-cp39-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\fer_pytorch\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Downloading google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
      "Using cached google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "Using cached pydantic_core-2.23.4-cp39-none-win_amd64.whl (1.9 MB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: uritemplate, pydantic-core, pyasn1, proto-plus, httplib2, googleapis-common-protos, cachetools, rsa, pyasn1-modules, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed cachetools-5.5.2 google-ai-generativelanguage-0.6.15 google-api-core-2.24.2 google-api-python-client-2.169.0 google-auth-2.40.1 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-core-2.23.4 rsa-4.9.1 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550e3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from typing import Dict, List, Tuple\n",
    "import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400c8a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gemini API Key loaded successfully!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "❌ Invalid dataset structure: {'tag': 'stress_situation', 'emotion': 'stress', 'scenario': \"You have a major deadline approaching, but you're feeling overwhelmed. What do you do?\", 'responses': [{'option': 'Take a break and go for a short walk.', 'reward': 2}, {'option': 'Panic and procrastinate until the last minute.', 'reward': -3}, {'option': 'Make a plan and break the task into smaller steps.', 'reward': 3}, {'option': 'Ignore the deadline and watch TV instead.', 'reward': -2}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 252\u001b[0m\n\u001b[0;32m    249\u001b[0m     evaluate_model(env, num_tests\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 252\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 243\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m    242\u001b[0m     load_api_key()\n\u001b[1;32m--> 243\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mEmotionGameEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     train_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain new model? (y/n): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_new:\n",
      "Cell \u001b[1;32mIn[5], line 69\u001b[0m, in \u001b[0;36mEmotionGameEnv.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstress_metrics \u001b[38;5;241m=\u001b[39m StressMetrics()\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction_history \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m intent \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintents\u001b[39m\u001b[38;5;124m\"\u001b[39m, []):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m intent \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m required_keys):\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Invalid dataset structure: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mintent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m intent[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponses\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[1;31mValueError\u001b[0m: ❌ Invalid dataset structure: {'tag': 'stress_situation', 'emotion': 'stress', 'scenario': \"You have a major deadline approaching, but you're feeling overwhelmed. What do you do?\", 'responses': [{'option': 'Take a break and go for a short walk.', 'reward': 2}, {'option': 'Panic and procrastinate until the last minute.', 'reward': -3}, {'option': 'Make a plan and break the task into smaller steps.', 'reward': 3}, {'option': 'Ignore the deadline and watch TV instead.', 'reward': -2}]}"
     ]
    }
   ],
   "source": [
    "# Full Version: Emotion-Based RL with Gemini API Integration\n",
    "# Load Gemini API Key\n",
    "def load_api_key() -> None:\n",
    "    env_path = \"../models/key.env\"\n",
    "    load_dotenv(env_path)\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\") or \"AIzaSyCcE1d9GrpAGiQh3Xrqlhs5E_wx4oAZ4d8\"\n",
    "    if not api_key:\n",
    "        raise ValueError(\"❌ Gemini API Key not found.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"✅ Gemini API Key loaded successfully!\")\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset() -> List[Dict]:\n",
    "    dataset_path = \"../datasets/game.json\"\n",
    "    try:\n",
    "        with open(dataset_path, \"r\") as file:\n",
    "            dataset = json.load(file)\n",
    "        required_keys = {\"scenario\", \"responses\", \"correct_response\", \"difficulty\"}\n",
    "        for intent in dataset.get(\"intents\", []):\n",
    "            if not all(key in intent for key in required_keys):\n",
    "                raise ValueError(f\"❌ Invalid dataset structure: {intent}\")\n",
    "            for response in intent[\"responses\"]:\n",
    "                if \"text\" not in response or \"reward\" not in response:\n",
    "                    raise ValueError(\"❌ Each response must have 'text' and 'reward'\")\n",
    "        print(f\"✅ Dataset loaded successfully with {len(dataset['intents'])} scenarios!\")\n",
    "        return dataset[\"intents\"]\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"❌ Dataset file '{dataset_path}' not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"❌ Failed to parse JSON file '{dataset_path}'.\")\n",
    "\n",
    "# Stress tracking\n",
    "class StressMetrics:\n",
    "    def __init__(self):\n",
    "        self.stress_level = 0\n",
    "        self.stress_history = []\n",
    "        self.response_times = []\n",
    "        self.incorrect_choices = 0\n",
    "        self.correct_choices = 0\n",
    "\n",
    "    def update_stress(self, reward: float, response_time: float) -> None:\n",
    "        stress_change = 0\n",
    "        if reward < 0:\n",
    "            self.incorrect_choices += 1\n",
    "            stress_change = 0.2\n",
    "        else:\n",
    "            self.correct_choices += 1\n",
    "            stress_change = -0.1\n",
    "        stress_change += min(response_time / 10, 0.5)\n",
    "        self.stress_level = max(0, min(1, self.stress_level + stress_change))\n",
    "        self.stress_history.append(self.stress_level)\n",
    "        self.response_times.append(response_time)\n",
    "\n",
    "    def get_summary(self) -> Dict:\n",
    "        return {\n",
    "            \"current_stress\": self.stress_level,\n",
    "            \"average_stress\": sum(self.stress_history) / len(self.stress_history) if self.stress_history else 0,\n",
    "            \"correct_choices\": self.correct_choices,\n",
    "            \"incorrect_choices\": self.incorrect_choices,\n",
    "            \"average_response_time\": sum(self.response_times) / len(self.response_times) if self.response_times else 0\n",
    "        }\n",
    "\n",
    "# Environment\n",
    "class EmotionGameEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dataset = load_dataset()\n",
    "        self.stress_metrics = StressMetrics()\n",
    "        self.interaction_history = []\n",
    "        self.current_episode = 0\n",
    "        self.emotions = [\"sad\", \"angry\", \"happy\", \"stress\", \"neutral\", \"fear\", \"anxious\"]\n",
    "        self.difficulty_levels = [\"easy\", \"medium\", \"hard\"]\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"emotion\": spaces.Discrete(len(self.emotions)),\n",
    "            \"difficulty\": spaces.Discrete(len(self.difficulty_levels))\n",
    "        })\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.max_episode_length = 10\n",
    "        self.state = None\n",
    "        self.current_scenario = None\n",
    "        self.episode_step = 0\n",
    "        self.available_scenarios = self._categorize_scenarios()\n",
    "\n",
    "    def _categorize_scenarios(self) -> Dict[str, List[Dict]]:\n",
    "        categorized = defaultdict(list)\n",
    "        for scenario in self.dataset:\n",
    "            categorized[scenario.get(\"emotion\", \"neutral\")].append(scenario)\n",
    "        return categorized\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_episode += 1\n",
    "        self.episode_step = 0\n",
    "        emotion = random.choice(self.emotions)\n",
    "        difficulty = random.choice(self.difficulty_levels)\n",
    "        possible_scenarios = [s for s in self.available_scenarios.get(emotion, []) if s.get(\"difficulty\") == difficulty]\n",
    "        if not possible_scenarios:\n",
    "            possible_scenarios = self.dataset\n",
    "        self.current_scenario = random.choice(possible_scenarios)\n",
    "        self.state = {\n",
    "            \"emotion\": self.emotions.index(emotion),\n",
    "            \"difficulty\": self.difficulty_levels.index(difficulty)\n",
    "        }\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action: int) -> Tuple[Dict, float, bool, Dict]:\n",
    "        start_time = time.time()\n",
    "        self.episode_step += 1\n",
    "        try:\n",
    "            responses = self.current_scenario[\"responses\"]\n",
    "            if action >= len(responses):\n",
    "                reward = -1\n",
    "                response_data = {\"text\": \"Invalid choice\", \"reward\": reward}\n",
    "            else:\n",
    "                response_data = responses[action]\n",
    "                reward = response_data[\"reward\"]\n",
    "                difficulty = self.difficulty_levels[self.state[\"difficulty\"]]\n",
    "                if difficulty == \"hard\":\n",
    "                    reward *= 1.5\n",
    "                elif difficulty == \"easy\":\n",
    "                    reward *= 0.8\n",
    "        except:\n",
    "            reward = -1\n",
    "            response_data = {\"text\": \"Error in scenario\", \"reward\": reward}\n",
    "\n",
    "        response_time = time.time() - start_time\n",
    "        self.stress_metrics.update_stress(reward, response_time)\n",
    "\n",
    "        self.interaction_history.append({\n",
    "            \"episode\": self.current_episode,\n",
    "            \"step\": self.episode_step,\n",
    "            \"emotion\": self.emotions[self.state[\"emotion\"]],\n",
    "            \"scenario\": self.current_scenario[\"scenario\"],\n",
    "            \"action\": action,\n",
    "            \"response\": response_data[\"text\"],\n",
    "            \"reward\": reward,\n",
    "            \"response_time\": response_time,\n",
    "            \"stress_level\": self.stress_metrics.stress_level\n",
    "        })\n",
    "\n",
    "        done = self.episode_step >= self.max_episode_length or reward < -0.5\n",
    "\n",
    "        info = {\n",
    "            \"scenario\": self.current_scenario[\"scenario\"],\n",
    "            \"response\": response_data[\"text\"],\n",
    "            \"stress_level\": self.stress_metrics.stress_level,\n",
    "            \"correct_response\": self.current_scenario.get(\"correct_response\", \"\"),\n",
    "            \"difficulty\": self.difficulty_levels[self.state[\"difficulty\"]]\n",
    "        }\n",
    "\n",
    "        next_state = {\n",
    "            \"emotion\": self.state[\"emotion\"],\n",
    "            \"difficulty\": random.choice([self.state[\"difficulty\"]] * 3 + [max(0, self.state[\"difficulty\"] - 1), min(len(self.difficulty_levels)-1, self.state[\"difficulty\"] + 1)])\n",
    "        }\n",
    "        return next_state, reward, done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'human':\n",
    "            print(f\"\\nEmotion: {self.emotions[self.state['emotion']]}, Difficulty: {self.difficulty_levels[self.state['difficulty']]}, Scenario: {self.current_scenario['scenario']}, Stress Level: {self.stress_metrics.stress_level:.2f}\")\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.interaction_history\n",
    "\n",
    "    def get_stress_summary(self):\n",
    "        return self.stress_metrics.get_summary()\n",
    "\n",
    "# Gemini-based therapy\n",
    "\n",
    "def get_therapy_response(emotion: str, scenario: str, stress_level: float, history: List[Dict]) -> str:\n",
    "    recent_history = history[-3:] if history else []\n",
    "    context = \"\\n\".join(\n",
    "        f\"Previous interaction: When feeling {h['emotion']} in situation '{h['scenario']}', the response was '{h['response']}' resulting in reward {h['reward']:.1f} and stress {h['stress_level']:.2f}.\"\n",
    "        for h in recent_history\n",
    "    )\n",
    "\n",
    "    therapy_approaches = {\n",
    "        \"stress\": \"cognitive behavioral therapy\",\n",
    "        \"anxious\": \"grounding and mindfulness\",\n",
    "        \"angry\": \"anger management\",\n",
    "        \"sad\": \"positive reframing\",\n",
    "        \"happy\": \"positive reinforcement\",\n",
    "        \"fear\": \"exposure therapy\",\n",
    "        \"neutral\": \"general counseling\"\n",
    "    }\n",
    "    approach = therapy_approaches.get(emotion, \"general counseling\")\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a compassionate AI therapist trained in CBT, DBT, and mindfulness.\\n\"\n",
    "        f\"The user feels {emotion} (stress level {stress_level:.2f}) in scenario: '{scenario}'.\\n\"\n",
    "        f\"Use {approach} to help them.\\n\"\n",
    "        f\"Here is context:\\n{context}\\nTherapeutic response:\"\n",
    "    )\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\"gemini-pro\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Error from Gemini: {e}\"\n",
    "\n",
    "# Training\n",
    "\n",
    "def train_rl_model(env: EmotionGameEnv, total_timesteps: int = 20000) -> PPO:\n",
    "    check_env(env)\n",
    "    eval_callback = EvalCallback(\n",
    "        env,\n",
    "        callback_on_new_best=StopTrainingOnRewardThreshold(reward_threshold=5.0, verbose=1),\n",
    "        verbose=1,\n",
    "        eval_freq=1000,\n",
    "        best_model_save_path=\"./best_models/\"\n",
    "    )\n",
    "    model = PPO(\"MultiInputPolicy\", env, verbose=1, learning_rate=0.0003, tensorboard_log=\"./tensorboard_logs/\")\n",
    "    model.learn(total_timesteps=total_timesteps, callback=eval_callback)\n",
    "    model.save(\"emotional_rl_agent_enhanced\")\n",
    "    return model\n",
    "\n",
    "# Evaluation\n",
    "\n",
    "def evaluate_model(env: EmotionGameEnv, model_path: str = \"emotional_rl_agent_enhanced\", num_tests: int = 5):\n",
    "    print(\"\\n📊 Evaluation Started\")\n",
    "    try:\n",
    "        model = PPO.load(model_path)\n",
    "    except:\n",
    "        print(\"Model not found.\")\n",
    "        return\n",
    "\n",
    "    for test in range(num_tests):\n",
    "        print(f\"\\n=== Test Case {test+1} ===\")\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            env.render()\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            emotion = env.emotions[obs[\"emotion\"]]\n",
    "            gpt_response = get_therapy_response(emotion, info[\"scenario\"], env.stress_metrics.stress_level, env.get_history())\n",
    "            print(f\"\\nTherapeutic Feedback: {gpt_response}\")\n",
    "\n",
    "# Entry\n",
    "\n",
    "def main():\n",
    "    load_api_key()\n",
    "    env = EmotionGameEnv()\n",
    "    train_new = input(\"Train new model? (y/n): \").lower() == 'y'\n",
    "    if train_new:\n",
    "        model = train_rl_model(env)\n",
    "    else:\n",
    "        model = PPO.load(\"emotional_rl_agent_enhanced\")\n",
    "    evaluate_model(env, num_tests=3)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fer_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
